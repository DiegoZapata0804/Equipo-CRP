{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competencia: Clasificación de Péptidos Antimicrobianos\n",
    "\n",
    "El equipo está conformado por:\n",
    "\n",
    "    Angie Melissa Calderón Albarracin\n",
    "    Diego Alejandro Zapata Alcaraz\n",
    "    Juan David Valencia Quiceno\n",
    "    Juan Esteban Arroyave Duque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar paquetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import naive_bayes\n",
    "#from sklearn.feature_selection import RFE\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de los datos positivos (8322, 1762)\n",
      "Forma de los datos negativos (5561, 1761)\n",
      "Forma de los datos validacion (1623, 1763)\n",
      "Forma de los datos del preprocesamiento (15506, 1763)\n"
     ]
    }
   ],
   "source": [
    "#Cargar la data\n",
    "data_positiva=pd.read_csv('Datos/DatosPositivos1.csv')\n",
    "data_negativa=pd.read_csv('Datos/DatosNegativos1.csv')\n",
    "#data_validacion=pd.read_csv('Datos/DatosValidacion1.csv')\n",
    "\n",
    "data_positiva['Tipo']='Train'\n",
    "data_negativa['Tipo']='Train'\n",
    "data_validacion['Tipo']='Test'\n",
    "\n",
    "data_pre=pd.concat([data_positiva,data_negativa,data_validacion])\n",
    "#Nota: La clase 1, corresponde a los péptidos que SON antimicrobianos, 0 los que no.\n",
    "# Adicional los datos están desbalanceados en la siguiente relacion 60% son positivos 40% negativos.\n",
    "\n",
    "print('Forma de los datos positivos',data_positiva.shape)\n",
    "print('Forma de los datos negativos',data_negativa.shape)\n",
    "print('Forma de los datos validacion',data_validacion.shape)\n",
    "print('Forma de los datos del preprocesamiento',data_pre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos\n",
    "    1.Identificación de colummnas adicionales o diferentes entre los datos\n",
    "    2.Eliminicación de columnas con más 20% de null y nan (Es posible el llenado)\n",
    "    3.Filtrado de varianza\n",
    "    4.Correlación entre las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 No se encuentra\n",
      "Unnamed: 0.1 No se encuentra\n"
     ]
    }
   ],
   "source": [
    "# Encontrar las columnas que no se encuentra en los datasets (positivo, negativo y validación)\n",
    "col_val=data_validacion.columns\n",
    "col_pos=data_positiva.columns\n",
    "col_neg=data_negativa.columns\n",
    "\n",
    "for i in col_val:\n",
    "    if i not in col_neg:\n",
    "        print(i, 'No se encuentra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimianción de columnas con mayor cantidad de null o nan\n",
    "aux=(data_pre.isnull().sum()/len(data_pre))*100\n",
    "col_total=data_pre.columns\n",
    "col_remove=[col_total[i] for i in range(len(col_total)) if aux[i]>=20]\n",
    "\n",
    "data_pre=data_pre.drop(col_remove,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación de columnas por baja varianza.\n",
    "#En primera instancia se seleccionan las columnas numéricas, luego se retira la columna 'class' porque es nuestra vble y\n",
    "a=data_pre.var()\n",
    "a.drop('class')\n",
    "col_total=data_pre.columns\n",
    "\n",
    "col_ana=[col_total[i] for i in range(len(a)) if a[i]<=0.001]\n",
    "col_ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charge</th>\n",
       "      <th>taugrant30</th>\n",
       "      <th>QSOgrant1</th>\n",
       "      <th>QSOgrant2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15506.000000</td>\n",
       "      <td>15506.000000</td>\n",
       "      <td>15506.000000</td>\n",
       "      <td>15506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.869740</td>\n",
       "      <td>0.116402</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>0.014927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.017698</td>\n",
       "      <td>0.426620</td>\n",
       "      <td>0.023763</td>\n",
       "      <td>0.029479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-13.894000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.004000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.793000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.004394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.016778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.996000</td>\n",
       "      <td>4.419000</td>\n",
       "      <td>0.524904</td>\n",
       "      <td>0.771977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             charge    taugrant30     QSOgrant1     QSOgrant2\n",
       "count  15506.000000  15506.000000  15506.000000  15506.000000\n",
       "mean       1.869740      0.116402      0.013334      0.014927\n",
       "std        3.017698      0.426620      0.023763      0.029479\n",
       "min      -13.894000      0.000000      0.000000      0.000000\n",
       "25%       -0.004000      0.000000      0.000000      0.000000\n",
       "50%        1.793000      0.000000      0.005501      0.004394\n",
       "75%        3.860000      0.000000      0.016044      0.016778\n",
       "max       21.996000      4.419000      0.524904      0.771977"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pre[['charge',\n",
    " 'taugrant30',\n",
    " 'QSOgrant1',\n",
    " 'QSOgrant2']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap = sns.diverging_palette(h_neg=10,h_pos=240,as_cmap=True)\n",
    "#sns.heatmap(data_pre.corr(), center=0,cmap=cmap, linewidths=1,annot=True, fmt=\".2f\")\n",
    "data_pre.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandariazación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volviendo a la estructura original\n",
    "data_train=data_pre[data_pre['Tipo']=='Train']\n",
    "data_val=data_pre[data_pre['Tipo']=='Test']\n",
    "\n",
    "data_train=data_train.drop(['Tipo'],axis=1)\n",
    "data_test=data_val.drop(['Tipo'],axis=1)\n",
    "\n",
    "y=data_train.pop('class')\n",
    "X=data_train\n",
    "\n",
    "y_val=data_val.pop('class')\n",
    "X_val=data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraer la columnas con valores numéricos\n",
    "col_num1=[i for i in X_train.columns if \"int\" in str(X_train[i].dtype) or \"float\" in str(X_train[i].dtype)]\n",
    "col_num2=[i for i in X_test.columns if \"int\" in str(X_test[i].dtype) or \"float\" in str(X_test[i].dtype)]\n",
    "\n",
    "#creación del modelo de normalización\n",
    "scaler=StandardScaler()\n",
    "X_train_std=scaler.fit_transform(X_train[col_num1])\n",
    "X_test_std=scaler.transform(X_test[col_num2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de los modelos de clasificación\n",
    "\n",
    "Los modelos con los cuales trabajaremos son:\n",
    "    \n",
    "    1.LogisticRegressor\n",
    "    2.RandomForest\n",
    "    3.Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regresión Logistica\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador: 87.36 \n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test_std)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print (\"Precisión del clasificador Logitica: %.2f \" %(acc*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "#Una SVM Lineal\n",
    "#Una SVM de base Radial y\n",
    "#Una SVM Polinomial\n",
    "\n",
    "svm_lineal = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, random_state=0)\n",
    "svm_poly = SVC(kernel='poly', C=1.0, random_state=0)\n",
    "\n",
    "# Entrenamos los modelos\n",
    "svm_lineal.fit(X_train_std, y_train)\n",
    "svm_rbf.fit(X_train_std, y_train)\n",
    "svm_poly.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador Lineal: 87.18 \n",
      "Precisión del clasificador Radial: 91.11 \n",
      "Precisión del clasificador Polinomial: 87.94 \n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_lineal.predict(X_test_std)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print (\"Precisión del clasificador Lineal: %.2f \" %(acc*100.0))\n",
    "\n",
    "y_pred = svm_rbf.predict(X_test_std)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print (\"Precisión del clasificador Radial: %.2f \" %(acc*100.0))\n",
    "\n",
    "y_pred = svm_poly.predict(X_test_std)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print (\"Precisión del clasificador Polinomial: %.2f \" %(acc*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "nv = naive_bayes.GaussianNB()\n",
    "nv.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador Radial: 75.77 \n"
     ]
    }
   ],
   "source": [
    "y_pred = nv.predict(X_test_std)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print (\"Precisión del clasificador Radial: %.2f \" %(acc*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
